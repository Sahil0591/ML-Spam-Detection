{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BP_KVzUNZgk7"
   },
   "source": [
    "# Introduction\n",
    "This colab worksheet provides a starting point for Task 1 (the natural language processing assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AOixuUruWuF4"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix as sk_confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUvmUp0zXwBG"
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oeQIUdp0TUBQ",
    "outputId": "c75dd4ff-5b78-4390-8113-c7e59421dcb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    2551\n",
      "1    1068\n",
      "Name: count, dtype: int64\n",
      "(3619,) (3619,)\n",
      "(1552,)\n"
     ]
    }
   ],
   "source": [
    "# Load the data using np.load\n",
    "data = pd.read_csv('data/spam_detection_training_data.csv')\n",
    "\n",
    "# Checking number of Not Spam(0) & Spam(1)\n",
    "print(data['label'].value_counts())\n",
    "\n",
    "# Extract the text and the labels\n",
    "text = data['text'].values\n",
    "labels = data['label'].values\n",
    "\n",
    "test_data = pd.read_csv('data/spam_detection_test_data.csv')\n",
    "test_text = test_data['text'].values\n",
    "\n",
    "print(text.shape, labels.shape)\n",
    "print(test_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ttfUbA-Z0hs"
   },
   "source": [
    "# Data Visualisation\n",
    "Here's an example of how to display the text based on its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-MI-K_6m3K4",
    "outputId": "eaa739bb-e4ee-44fd-8746-fb87fa5430c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: noms / actual flow for 3 / 19 / 01\n",
      "we agree with the nom . for 3 / 19 / 01 .\n",
      "- - - - - - - - - - - - - - - - - - - - - - forwarded by david avila / lsp / enserch / us on 03 / 20 / 2001\n",
      "01 : 24 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\" eileen ponton \" on 03 / 20 / 2001 10 : 05 : 59 am\n",
      "to : david avila / lsp / enserch / us @ tu , charlie stone / texas utilities @ tu , melissa\n",
      "jones / texas utilities @ tu , hpl . scheduling @ enron . com , liz . bellamy @ enron . com\n",
      "cc :\n",
      "subject : noms / actual flow for 3 / 19 / 01\n",
      "date nom mcf mmbtu\n",
      "3 / 19 / 01 60 , 000 59 , 944 61 , 562\n",
      "btu = 1 . 027 \n",
      "is not spam!\n"
     ]
    }
   ],
   "source": [
    "# Examples of Spam and not Spam\n",
    "def print_text(text, label):\n",
    "  if label == 0:\n",
    "    print (text, '\\nis not spam!')\n",
    "  else:\n",
    "    print (text, '\\nis spam!')\n",
    "\n",
    "idx = np.random.randint(0, text.shape[0])\n",
    "print_text(text[idx], labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In3Qzn4ZaZv1"
   },
   "source": [
    "# Calculating Confusion Matrix and exporting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRsNDVn1JLnI",
    "outputId": "f1773364-2ea9-4af8-f058-e595e909fe1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define stopwords once\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Text preprocessing function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # remove punctuation and numbers\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+|\\S+\\.(com|net|org|co|in|uk)', '', text)\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "data['clean_text'] = data['text'].map(clean_text)\n",
    "test_data['clean_text'] = test_data['text'].map(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IJSS7DrSJMvI"
   },
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit on training data and transform both\n",
    "x_train_full = vectorizer.fit_transform(data['clean_text']).toarray()\n",
    "y_train_full = data['label']\n",
    "\n",
    "x_test = vectorizer.transform(test_data['clean_text']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9vWDAqwAnfAW"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(true_labels, pred_labels):\n",
    "    cm = sk_confusion_matrix(true_labels, pred_labels)\n",
    "    print(\"Confusion Matrix:\\n\")\n",
    "    print(cm)\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfExvTcSJS9u",
    "outputId": "a193bfac-d20c-4017-d420-db0ec1013858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing model: Naive Bayes\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[487  22]\n",
      " [  9 206]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       509\n",
      "           1       0.90      0.96      0.93       215\n",
      "\n",
      "    accuracy                           0.96       724\n",
      "   macro avg       0.94      0.96      0.95       724\n",
      "weighted avg       0.96      0.96      0.96       724\n",
      "\n",
      "None\n",
      "____________________________________________________\n",
      "\n",
      "\n",
      "Testing model: Logistic Regression\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[500   9]\n",
      " [  3 212]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       509\n",
      "           1       0.96      0.99      0.97       215\n",
      "\n",
      "    accuracy                           0.98       724\n",
      "   macro avg       0.98      0.98      0.98       724\n",
      "weighted avg       0.98      0.98      0.98       724\n",
      "\n",
      "None\n",
      "____________________________________________________\n",
      "\n",
      "\n",
      "Testing model: Linear SVC\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[499  10]\n",
      " [  5 210]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       509\n",
      "           1       0.95      0.98      0.97       215\n",
      "\n",
      "    accuracy                           0.98       724\n",
      "   macro avg       0.97      0.98      0.98       724\n",
      "weighted avg       0.98      0.98      0.98       724\n",
      "\n",
      "None\n",
      "____________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\sahil\\github\\279060\\279060\\task 1\\venv\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the training data for validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Linear SVC\": LinearSVC()\n",
    "}\n",
    "\n",
    "for name, clf in models.items():\n",
    "\n",
    "    print(f\"\\nTesting model: {name}\\n\")\n",
    "    clf.fit(x_train, y_train)\n",
    "    preds = clf.predict(x_val)\n",
    "\n",
    "    print(confusion_matrix(y_val, preds))\n",
    "\n",
    "    print(\"____________________________________________________\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ApC2M6XYph11"
   },
   "outputs": [],
   "source": [
    "def save_as_csv(pred_labels, location = '.'):\n",
    "\n",
    "    assert pred_labels.shape[0] == 1552, 'Error: wrong number of labels, should be 1552 test labels'\n",
    "\n",
    "    if len(pred_labels.shape) == 1:\n",
    "        pred_labels = pred_labels.reshape(-1, 1)\n",
    "\n",
    "    np.savetxt(location + '/results_task1.csv', pred_labels, delimiter=',', fmt='%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8hQn8G80UtKq"
   },
   "outputs": [],
   "source": [
    "# Retrain the best model on the full training data\n",
    "best_model = LogisticRegression(max_iter=1000)\n",
    "best_model.fit(x_train_full, y_train_full)\n",
    "\n",
    "# Predict on already vectorized test data\n",
    "test_preds = best_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HEVB2g8_VwyA"
   },
   "outputs": [],
   "source": [
    "# Saving locally\n",
    "save_as_csv(test_preds, location='results')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
